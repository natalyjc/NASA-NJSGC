{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f427aaa-4c47-4c3b-9b56-f772bd9d7096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88475df4-2859-458b-ac8d-9738956d0623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using SDBD Close-Approach Data API, getting all Earth close approach data for NEOs on or after Jan 01, 2004 up to June 1, 2024\n",
    "# data of 10 years\n",
    "data_url = \"https://ssd-api.jpl.nasa.gov/cad.api?date-min=2004-01-01&date-max=2024-06-01\"\n",
    "r = requests.get(data_url)\n",
    "data = json.loads(r.text)\n",
    "\n",
    "fields = data['fields']\n",
    "data_list = data['data']\n",
    "\n",
    "df = pd.DataFrame(data_list, columns=fields)\n",
    "df.to_csv('neo_data.csv', index=False) # this outputs a dataset of ~15000 entries, with the first 11 columns from the SBDB API\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659761cd-03cd-4557-a144-0c5ba56d181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm # to track progress and time taken to extract data\n",
    "\n",
    "API_KEY = \"tysPTsV4so1r7Mz7zLsllXXjEwyoabBsmw8wMGtx\"\n",
    "BASE_URL = \"https://api.nasa.gov/neo/rest/v1/neo/{des}?api_key=\" + API_KEY\n",
    "\n",
    "file_path = 'neo_data.csv'\n",
    "neo_data = pd.read_csv(file_path)\n",
    "\n",
    "# define new columns/data to be extracted from NASA API\n",
    "new_columns = [\n",
    "    'estimated_diameter_min_km', 'estimated_diameter_max_km', 'data_arc_in_days', \n",
    "    'observations_used', 'orbit_uncertainty', 'minimum_orbit_intersection',\n",
    "    'jupiter_tisserand_invariant', 'epoch_osculation', 'eccentricity', \n",
    "    'semi_major_axis', 'inclination', 'ascending_node_longitude',\n",
    "    'orbital_period', 'perihelion_distance', 'perihelion_argument', \n",
    "    'aphelion_distance', 'perihelion_time', 'mean_anomaly', 'mean_motion',\n",
    "    'is_potentially_hazardous_asteroid'\n",
    "]\n",
    "\n",
    "# adding new columns to neo data df, initializing with None values\n",
    "for col in new_columns:\n",
    "    neo_data[col] = None \n",
    "\n",
    "# fetch data from the NASA API\n",
    "def fetch_neo_data(des):\n",
    "    try:\n",
    "        response = requests.get(BASE_URL.format(des=des)) # HTTP get request to NASA API\n",
    "        response.raise_for_status()  # HTTP errors\n",
    "        data = response.json() # converting JSON response from NASA API to dict\n",
    "        return {\n",
    "            # features to be extracted \n",
    "            'estimated_diameter_min_km': data['estimated_diameter']['kilometers']['estimated_diameter_min'],\n",
    "            'estimated_diameter_max_km': data['estimated_diameter']['kilometers']['estimated_diameter_max'],\n",
    "            'data_arc_in_days': data['orbital_data']['data_arc_in_days'],\n",
    "            'observations_used': data['orbital_data']['observations_used'],\n",
    "            'orbit_uncertainty': data['orbital_data']['orbit_uncertainty'],\n",
    "            'minimum_orbit_intersection': data['orbital_data']['minimum_orbit_intersection'],\n",
    "            'jupiter_tisserand_invariant': data['orbital_data']['jupiter_tisserand_invariant'],\n",
    "            'epoch_osculation': data['orbital_data']['epoch_osculation'],\n",
    "            'eccentricity': data['orbital_data']['eccentricity'],\n",
    "            'semi_major_axis': data['orbital_data']['semi_major_axis'],\n",
    "            'inclination': data['orbital_data']['inclination'],\n",
    "            'ascending_node_longitude': data['orbital_data']['ascending_node_longitude'],\n",
    "            'orbital_period': data['orbital_data']['orbital_period'],\n",
    "            'perihelion_distance': data['orbital_data']['perihelion_distance'],\n",
    "            'perihelion_argument': data['orbital_data']['perihelion_argument'],\n",
    "            'aphelion_distance': data['orbital_data']['aphelion_distance'],\n",
    "            'perihelion_time': data['orbital_data']['perihelion_time'],\n",
    "            'mean_anomaly': data['orbital_data']['mean_anomaly'],\n",
    "            'mean_motion': data['orbital_data']['mean_motion'],\n",
    "            'is_potentially_hazardous_asteroid': data['is_potentially_hazardous_asteroid'] # label\n",
    "        }\n",
    "    # handling objects that are looked up and not in the NASA API\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API request failed for {des}: {e}\")\n",
    "        return {}\n",
    "\n",
    "# for each row, fetch data from API, then update neo_data df\n",
    "request_count = 0 \n",
    "start_time = time.time()\n",
    "# save_interval = 100  # saving neo_data df every 100 rows\n",
    "\n",
    "# https://github.com/softhints/Pandas-Tutorials/blob/master/tqdm/1.progress-bars-pandas-python-tqdm.ipynb\n",
    "for index, row in tqdm(neo_data.iterrows(), total=neo_data.shape[0]):\n",
    "    # if request count is less than 1000, show progress time\n",
    "    if request_count >= 1000: # 1000 requests per hour \n",
    "        elapsed_time = time.time() - start_time \n",
    "        sleep_time = 3600 - elapsed_time\n",
    "        if sleep_time > 0:\n",
    "            print(f\"Rate limit reached, sleeping for {sleep_time:.2f} seconds.\")\n",
    "            time.sleep(sleep_time)\n",
    "        start_time = time.time()\n",
    "        request_count = 0\n",
    "    # call fetch function for current object in 'des' col of neo_data df\n",
    "    api_data = fetch_neo_data(row['des']) # access value in 'des' col for current row, saving dictionary of data to api_data\n",
    "\n",
    "    # if api_data is not empty\n",
    "    if api_data: \n",
    "        # for each key, value in dict, update to neo_data df\n",
    "        for key, value in api_data.items():\n",
    "            neo_data.at[index, key] = value\n",
    "\n",
    "    request_count += 1 # increment request count\n",
    "\n",
    "    # code to print progress and save intermediate results every 100 entries\n",
    "    # if (index + 1) % save_interval == 0:\n",
    "        # print(f\"Processed {index + 1} rows. Saving intermediate results.\")\n",
    "        # neo_data.to_csv(f'intermediate_neo_data_{index + 1}.csv', index=False)\n",
    "\n",
    "# save expanded data to new csv file\n",
    "neo_data.to_csv('final_neo_data.csv', index=False)\n",
    "print(\"Data fetching complete. CSV file has been saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
