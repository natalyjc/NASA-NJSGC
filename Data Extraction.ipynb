{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f427aaa-4c47-4c3b-9b56-f772bd9d7096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm # to track progress and time taken to extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4defa5-ea57-4c31-a72a-1eabdf4c79d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using SDBD Close-Approach Data API, getting all Earth close approach data for NEOs on or after Jan 01, 2004 up to June 1, 2024\n",
    "\n",
    "data_url = \"https://ssd-api.jpl.nasa.gov/cad.api?date-min=2004-01-01&date-max=2024-06-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255878c3-3d99-4a0c-9edf-02af8b091175",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(data_url)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f62f3e-05c3-4445-a886-06025eede186",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(r.text)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7389cc52-6d5b-408e-8736-d64ea4f184ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = data['fields']\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f3a323-ff9a-46cc-8dea-78312cb36f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = data['data']\n",
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88475df4-2859-458b-ac8d-9738956d0623",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_list, columns=fields)\n",
    "df.to_csv('neo_data.csv', index=False) # this outputs a dataset of ~15000 entries, with the first 11 columns from the SBDB API\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659761cd-03cd-4557-a144-0c5ba56d181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"tysPTsV4so1r7Mz7zLsllXXjEwyoabBsmw8wMGtx\"\n",
    "BASE_URL = \"https://api.nasa.gov/neo/rest/v1/neo/{des}?api_key=\" + API_KEY\n",
    "\n",
    "file_path = 'neo_data.csv'\n",
    "neo_data = pd.read_csv(file_path)\n",
    "\n",
    "# define new columns/data to be extracted from NASA API\n",
    "new_columns = [\n",
    "    'estimated_diameter_min_km', 'estimated_diameter_max_km', 'data_arc_in_days', \n",
    "    'observations_used', 'orbit_uncertainty', 'minimum_orbit_intersection',\n",
    "    'jupiter_tisserand_invariant', 'epoch_osculation', 'eccentricity', \n",
    "    'semi_major_axis', 'inclination', 'ascending_node_longitude',\n",
    "    'orbital_period', 'perihelion_distance', 'perihelion_argument', \n",
    "    'aphelion_distance', 'perihelion_time', 'mean_anomaly', 'mean_motion',\n",
    "    'is_potentially_hazardous_asteroid'\n",
    "]\n",
    "\n",
    "# adding new columns to neo data df, initializing with None values\n",
    "for col in new_columns:\n",
    "    neo_data[col] = None \n",
    "\n",
    "# fetch data from the NASA API\n",
    "def fetch_neo_data(des):\n",
    "    try:\n",
    "        response = requests.get(BASE_URL.format(des=des)) # HTTP get request to NASA API\n",
    "        response.raise_for_status()  # HTTP errors\n",
    "        data = response.json() # converting JSON response from NASA API to dict\n",
    "        return {\n",
    "            # features to be extracted \n",
    "            'estimated_diameter_min_km': data['estimated_diameter']['kilometers']['estimated_diameter_min'],\n",
    "            'estimated_diameter_max_km': data['estimated_diameter']['kilometers']['estimated_diameter_max'],\n",
    "            'data_arc_in_days': data['orbital_data']['data_arc_in_days'],\n",
    "            'observations_used': data['orbital_data']['observations_used'],\n",
    "            'orbit_uncertainty': data['orbital_data']['orbit_uncertainty'],\n",
    "            'minimum_orbit_intersection': data['orbital_data']['minimum_orbit_intersection'],\n",
    "            'jupiter_tisserand_invariant': data['orbital_data']['jupiter_tisserand_invariant'],\n",
    "            'epoch_osculation': data['orbital_data']['epoch_osculation'],\n",
    "            'eccentricity': data['orbital_data']['eccentricity'],\n",
    "            'semi_major_axis': data['orbital_data']['semi_major_axis'],\n",
    "            'inclination': data['orbital_data']['inclination'],\n",
    "            'ascending_node_longitude': data['orbital_data']['ascending_node_longitude'],\n",
    "            'orbital_period': data['orbital_data']['orbital_period'],\n",
    "            'perihelion_distance': data['orbital_data']['perihelion_distance'],\n",
    "            'perihelion_argument': data['orbital_data']['perihelion_argument'],\n",
    "            'aphelion_distance': data['orbital_data']['aphelion_distance'],\n",
    "            'perihelion_time': data['orbital_data']['perihelion_time'],\n",
    "            'mean_anomaly': data['orbital_data']['mean_anomaly'],\n",
    "            'mean_motion': data['orbital_data']['mean_motion'],\n",
    "            'is_potentially_hazardous_asteroid': data['is_potentially_hazardous_asteroid'] # label\n",
    "        }\n",
    "    # handling objects that are looked up and not in the NASA API\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API request failed for {des}: {e}\")\n",
    "        return {}\n",
    "\n",
    "# for each row, fetch data from API, then update neo_data df\n",
    "request_count = 0 \n",
    "start_time = time.time()\n",
    "# save_interval = 100  # saving neo_data df every 100 rows\n",
    "\n",
    "# https://github.com/softhints/Pandas-Tutorials/blob/master/tqdm/1.progress-bars-pandas-python-tqdm.ipynb\n",
    "for index, row in tqdm(neo_data.iterrows(), total=neo_data.shape[0]):\n",
    "    # if request count is less than 1000, show progress time\n",
    "    if request_count >= 1000: # 1000 requests per hour \n",
    "        elapsed_time = time.time() - start_time \n",
    "        sleep_time = 3600 - elapsed_time\n",
    "        if sleep_time > 0:\n",
    "            print(f\"Rate limit reached, sleeping for {sleep_time:.2f} seconds.\")\n",
    "            time.sleep(sleep_time)\n",
    "        start_time = time.time()\n",
    "        request_count = 0\n",
    "    # call fetch function for current object in 'des' col of neo_data df\n",
    "    api_data = fetch_neo_data(row['des']) # access value in 'des' col for current row, saving dictionary of data to api_data\n",
    "\n",
    "    # if api_data is not empty\n",
    "    if api_data: \n",
    "        # for each key, value in dict, update to neo_data df\n",
    "        for key, value in api_data.items():\n",
    "            neo_data.at[index, key] = value\n",
    "\n",
    "    request_count += 1 # increment request count\n",
    "\n",
    "    # code to print progress and save intermediate results every 100 entries\n",
    "    # if (index + 1) % save_interval == 0:\n",
    "        # print(f\"Processed {index + 1} rows. Saving intermediate results.\")\n",
    "        # neo_data.to_csv(f'intermediate_neo_data_{index + 1}.csv', index=False)\n",
    "\n",
    "# save expanded data to new csv file\n",
    "neo_data.to_csv('final_neo_data.csv', index=False)\n",
    "print(\"Data fetching complete. CSV file has been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946f2ac-93b2-42f4-8034-c76d6bdb449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because data was orginally extracted using its 'des' as a lookup for the API request, it resulted in objects having NaN values for orbital features\n",
    "# Objects with NaN values will be extracted using its 'fullname', an optional parameter from the SBDB Close-Approach Data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4271026-a11c-4f0c-80b8-bf395c740c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using SDBD Close-Approach Data API, getting all Earth close approach data for NEOs on or after Jan 01, 2004 up to June 1, 2024 with fullname = true\n",
    "data_url_2 = \"https://ssd-api.jpl.nasa.gov/cad.api?date-min=2004-01-01&date-max=2024-06-01&fullname=true\"\n",
    "r_2 = requests.get(data_url_2)\n",
    "data_2 = json.loads(r_2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc205c-c547-40c2-b2e4-49191c8872ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_2 = data_2['fields']\n",
    "data_list_2 = data_2['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2231f7d6-cec1-410c-9208-a2700bf1a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame(data_list_2, columns=fields_2)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e97d5f8-d2d3-4ff2-9cda-02d4ca9badd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging 'fullname' column from the above dataframe to the final_neo_data file\n",
    "# this way\n",
    "final_neo_data = pd.read_csv('final_neo_data.csv')\n",
    "merged_df = pd.merge(final_neo_data, df_2[['des','fullname']], on='des', how='left')\n",
    "merged_df = merged_df.drop_duplicates(keep='first')\n",
    "merged_df.to_csv('merged_final_neo_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8be4ae-b639-4fb4-8fa9-f780cbdf7643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "API_KEY = \"tysPTsV4so1r7Mz7zLsllXXjEwyoabBsmw8wMGtx\"\n",
    "BASE_URL = \"https://api.nasa.gov/neo/rest/v1/neo/{fullname}?api_key=\" + API_KEY\n",
    "\n",
    "file_path = 'merged_final_neo_data.csv'\n",
    "neo_data = pd.read_csv(file_path)\n",
    "\n",
    "# define new columns/data to be extracted from NASA API\n",
    "new_columns = [\n",
    "    'estimated_diameter_min_km', 'estimated_diameter_max_km', 'data_arc_in_days', \n",
    "    'observations_used', 'orbit_uncertainty', 'minimum_orbit_intersection',\n",
    "    'jupiter_tisserand_invariant', 'epoch_osculation', 'eccentricity', \n",
    "    'semi_major_axis', 'inclination', 'ascending_node_longitude',\n",
    "    'orbital_period', 'perihelion_distance', 'perihelion_argument', \n",
    "    'aphelion_distance', 'perihelion_time', 'mean_anomaly', 'mean_motion',\n",
    "    'is_potentially_hazardous_asteroid'\n",
    "]\n",
    "\n",
    "# fetch data from the NASA API\n",
    "def fetch_neo_data(fullname):\n",
    "    try:\n",
    "        response = requests.get(BASE_URL.format(fullname=fullname)) # HTTP get request to NASA API\n",
    "        response.raise_for_status()  # HTTP errors\n",
    "        data = response.json() # converting JSON response from NASA API to dict\n",
    "        return {\n",
    "            # features to be extracted \n",
    "            'estimated_diameter_min_km': data['estimated_diameter']['kilometers']['estimated_diameter_min'],\n",
    "            'estimated_diameter_max_km': data['estimated_diameter']['kilometers']['estimated_diameter_max'],\n",
    "            'data_arc_in_days': data['orbital_data']['data_arc_in_days'],\n",
    "            'observations_used': data['orbital_data']['observations_used'],\n",
    "            'orbit_uncertainty': data['orbital_data']['orbit_uncertainty'],\n",
    "            'minimum_orbit_intersection': data['orbital_data']['minimum_orbit_intersection'],\n",
    "            'jupiter_tisserand_invariant': data['orbital_data']['jupiter_tisserand_invariant'],\n",
    "            'epoch_osculation': data['orbital_data']['epoch_osculation'],\n",
    "            'eccentricity': data['orbital_data']['eccentricity'],\n",
    "            'semi_major_axis': data['orbital_data']['semi_major_axis'],\n",
    "            'inclination': data['orbital_data']['inclination'],\n",
    "            'ascending_node_longitude': data['orbital_data']['ascending_node_longitude'],\n",
    "            'orbital_period': data['orbital_data']['orbital_period'],\n",
    "            'perihelion_distance': data['orbital_data']['perihelion_distance'],\n",
    "            'perihelion_argument': data['orbital_data']['perihelion_argument'],\n",
    "            'aphelion_distance': data['orbital_data']['aphelion_distance'],\n",
    "            'perihelion_time': data['orbital_data']['perihelion_time'],\n",
    "            'mean_anomaly': data['orbital_data']['mean_anomaly'],\n",
    "            'mean_motion': data['orbital_data']['mean_motion'],\n",
    "            'is_potentially_hazardous_asteroid': data['is_potentially_hazardous_asteroid'] # label\n",
    "        }\n",
    "    # handling objects that are looked up and not in the NASA API\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API request failed for {fullname}: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Identify rows with missing values\n",
    "rows_with_missing_values = neo_data[neo_data.isnull().any(axis=1)]\n",
    "\n",
    "# for each row, fetch data from API, then update neo_data df\n",
    "request_count = 0 \n",
    "start_time = time.time()\n",
    "\n",
    "for index, row in tqdm(rows_with_missing_values.iterrows(), total=rows_with_missing_values.shape[0]):\n",
    "    # if request count is less than 1000, show progress time\n",
    "    if request_count >= 1000: # 1000 requests per hour \n",
    "        elapsed_time = time.time() - start_time \n",
    "        sleep_time = 3600 - elapsed_time\n",
    "        if sleep_time > 0:\n",
    "            print(f\"Rate limit reached, sleeping for {sleep_time:.2f} seconds.\")\n",
    "            time.sleep(sleep_time)\n",
    "        start_time = time.time()\n",
    "        request_count = 0\n",
    "    \n",
    "    # Extract text within parentheses from 'fullname' column\n",
    "    fullname = row['fullname']\n",
    "    match = re.search(r'\\((.*?)\\)', fullname)\n",
    "    if match:\n",
    "        name_in_parentheses = match.group(1)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # call fetch function for current object in 'fullname' col of neo_data df\n",
    "    api_data = fetch_neo_data(name_in_parentheses) # access value in 'fullname' col for current row, saving dictionary of data to api_data\n",
    "\n",
    "    # if api_data is not empty\n",
    "    if api_data: \n",
    "        # for each key, value in dict, update to neo_data df\n",
    "        for key, value in api_data.items():\n",
    "            neo_data.at[index, key] = value\n",
    "\n",
    "    request_count += 1 # increment request count\n",
    "\n",
    "output_file_path = 'updated_neo_data.csv'\n",
    "neo_data.to_csv(output_file_path, index=False)\n",
    "print(\"Data fetching complete. CSV file has been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b69218-2bc7-4eb9-9de6-50ba9d512d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(BASE_URL)\n",
    "rate_limit_remaining = response.headers.get('X-RateLimit-Remaining')\n",
    "print(f\"Remaining API requests: {rate_limit_remaining}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
